{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験を実行する\n",
    "\n",
    "Azure Machine Learning SDK を使用して、メトリックを記録して出力を生成するコード実験を実行できます。これは、Azure Machine Learning におけるほとんどの機械学習操作の中核です。\n",
    "\n",
    "## ワークスペースに接続する\n",
    "\n",
    "すべての実験と関連リソースは、Azure Machine Learning ワークスペース内で管理されます。ほとんどの場合、ワークスペースの構成は JSON 構成ファイルに格納されます。これにより、Azure サブスクリプション ID などの詳細を覚えておく必要なく、簡単に再接続できます。Azure portal のワークスペースのブレードから JSON 構成ファイルをダウンロードできますが、ワークスペースでコンピューティング インスタンスを使用している場合、構成ファイルは既にルート フォルダーにダウンロードされています。\n",
    "\n",
    "次のコードでは、構成ファイルを使用してワークスペースに接続します。\n",
    "\n",
    "> **注**: Azure サブスクリプションでまだ認証済みのセッションを確立していない場合は、リンクをクリックして認証コードを入力し、Azure にサインインして認証するよう指示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験を実行する\n",
    "\n",
    "データ サイエンティストが実行する必要のある最も基本的なタスクの 1 つは、データを処理して分析する実験を作成して実行することです。この演習では、Azure ML の*実験*を使用して、Python コードを実行し、データから抽出された値を記録する方法を学習します。この場合、糖尿病の検査を受けた患者の詳細を含む単純なデータセットを使用します。データを探索し、統計情報、視覚化、およびデータ サンプルを抽出する実験を実行します。使用するコードのほとんどは、データ探索プロセスで実行されるなど、かなり汎用的な Python です。ただし、数行を追加すると、コードは Azure ML *実験*を使用して実行の詳細を記録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"mslearn-diabetes\")\n",
    "\n",
    "# Start logging data from the experiment, obtaining a reference to the experiment run\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the data from a local file\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "print('Analyzing {} rows of data'.format(row_count))\n",
    "\n",
    "# Plot and log the count of diabetic vs non-diabetic patients\n",
    "diabetic_counts = data['Diabetic'].value_counts()\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.gca()    \n",
    "diabetic_counts.plot.bar(ax = ax) \n",
    "ax.set_title('Patients with Diabetes') \n",
    "ax.set_xlabel('Diagnosis') \n",
    "ax.set_ylabel('Patients')\n",
    "plt.show()\n",
    "run.log_image(name='label distribution', plot=fig)\n",
    "\n",
    "# log distinct pregnancy counts\n",
    "pregnancies = data.Pregnancies.unique()\n",
    "run.log_list('pregnancy categories', pregnancies)\n",
    "\n",
    "# Log summary statistics for numeric columns\n",
    "med_columns = ['PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI']\n",
    "summary_stats = data[med_columns].describe().to_dict()\n",
    "for col in summary_stats:\n",
    "    keys = list(summary_stats[col].keys())\n",
    "    values = list(summary_stats[col].values())\n",
    "    for index in range(len(keys)):\n",
    "        run.log_row(col, stat=keys[index], value = values[index])\n",
    "        \n",
    "# Save a sample of the data and upload it to the experiment output\n",
    "data.sample(100).to_csv('sample.csv', index=False, header=True)\n",
    "run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行の詳細を表示する\n",
    "\n",
    "Jupyter Notebook では、**RunDetails** ウィジェットを使用して、実行の詳細を視覚化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Machine Learning Studio の詳細を表示する\n",
    "\n",
    "**RunDetails** ウィジェットには、Azure Machine Learning Studio で**実行の詳細を表示**するためのリンクが含まれていることに注意してください。これをクリックすると、実行の詳細を表示する新しいブラウザー タブが開きます ([Azure Machine Learning Studio](https://ml.azure.com) を開いて、**実験**ページで実行を検索することもできます)。Azure Machine Learning Studio での実行を表示する場合は、次の点に注意してください。\n",
    "\n",
    "- **[詳細]** タブには、実験実行の一般的なプロパティが含まれています。\n",
    "- **[メトリック]** タブでは、記録されたメトリックを選択し、表またはグラフとして表示できます。\n",
    "- **[イメージ]** タブでは、実験で記録された画像やプロットを選択して表示できます (この場合は、*ラベル分布*プロット)\n",
    "- **[子の実行]** タブには、子の実行が一覧表示されます (この実験では、何も表示されません)。\n",
    "- **[出力 + ログ]** タブには、実験で生成された出力ファイルまたはログ ファイルが表示されます。\n",
    "- **[スナップショット]** タブには、実験コードが実行されたフォルダー内のすべてのファイル (この場合は、このノートブックと同じフォルダー内のすべてファイル) が含まれます。\n",
    "- **[説明]** タブは、実験によって生成されたモデルの説明を表示するために使用されます (この場合は、何も表示されません)。\n",
    "- **[均等化]** タブは、機械学習モデルの公平性の評価に役立つ予測パフォーマンスの格差を視覚化するために使用されます (この場合は、何も表示されません)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDK を使用して実験の詳細を取得する\n",
    "\n",
    "以前に実行したコードの **run** 変数は **Run** オブジェクトのインスタンスで、Azure Machine Learning で実験の個々の実行を参照します。この参照を使用すると、実行とその出力に関する情報を得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get logged metrics\n",
    "print(\"Metrics:\")\n",
    "metrics = run.get_metrics()\n",
    "for metric_name in metrics:\n",
    "    print(metric_name, \":\", metrics[metric_name])\n",
    "\n",
    "# Get output files\n",
    "print(\"\\nFiles:\")\n",
    "files = run.get_file_names()\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実験で作成したファイルは、**download_file** メソッドを使用して個々に、または **download_files** メソッドを使用して複数のファイルを取得することでダウンロードできます。以下のコードを使って、実行の**output**フォルダーのファイルをすべてダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "download_folder = 'downloaded-files'\n",
    "\n",
    "# Download files in the \"outputs\" folder\n",
    "run.download_files(prefix='outputs', output_directory=download_folder)\n",
    "\n",
    "# Verify the files have been downloaded\n",
    "for root, directories, filenames in os.walk(download_folder): \n",
    "    for filename in filenames:  \n",
    "        print (os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実験実行のトラブルシューティングが必要な場合は、**get_details** メソッドを使用して実行に関する基本的な詳細を取得するか、**get_details_with_logs** メソッドを使用して実行の詳細と実行中に生成されたログ ファイルの内容を取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_details_with_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細には、実験が実行されたコンピューティング ターゲット、実験の開始日時、終了日時などの情報が含まれることに注意してください。さらに、実験コードを含むノートブック (このノート) は複製された Git リポジトリにあるため、リポジトリ、ブランチ、状態に関する詳細が実行履歴に記録されます。\n",
    "\n",
    "この場合は、詳細の **logFiles** エントリは、ログ ファイルが生成されていないことを示している点に留意してください。このようなインライン実験では、これは一般的なことですが、実験としてスクリプトを実行するとさらに興味深い状態になります。これからそれを見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験スクリプトを実行する\n",
    "\n",
    "前の例では、このノートブックで実験をインラインで実行しました。より柔軟なソリューションとして、実験用の別のスクリプトを作成し、必要な他のファイルと共にフォルダーに格納し、Azure ML を使用してフォルダー内のスクリプトに基づいて実験を実行します。\n",
    "\n",
    "まず、実験ファイルのフォルダーを作成し、データをコピーします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "folder_name = 'diabetes-experiment-files'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、実験用のコードを含む Python スクリプトを作成し、実験フォルダーに保存します。\n",
    "\n",
    "> **注**: 次のセルを実行するとスクリプト ファイルが*作成されます*が、実行されません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $folder_name/diabetes_experiment.py\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "print('Analyzing {} rows of data'.format(row_count))\n",
    "\n",
    "# Count and log the label counts\n",
    "diabetic_counts = data['Diabetic'].value_counts()\n",
    "print(diabetic_counts)\n",
    "for k, v in diabetic_counts.items():\n",
    "    run.log('Label:' + str(k), v)\n",
    "      \n",
    "# Save a sample of the data in the outputs folder (which gets uploaded automatically)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードは、以前に使用したインライン コードの簡略化されたバージョンです。ただし、次の点に注意してください。\n",
    "- スクリプトの実行時に実験の実行コンテキストを取得するために、`Run.get_context()` メソッドを使用します。\n",
    "- スクリプトが配置されているフォルダーから糖尿病データを読み込みます。\n",
    "- **outputs** という名前のフォルダーを作成し、サンプルファイルをそれに書き込みます - このフォルダーは自動的に実験実行にアップロードされます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、実験を実行する準備がほぼ整いました。スクリプトを実行するには、実験で実行する Python スクリプト ファイルを識別する **ScriptRunConfig** を作成し、それに基づいて実験を実行する必要があります。\n",
    "\n",
    "> **注**: ScriptRunConfig は、コンピューティング ターゲットと Python 環境も決定します。この場合、Python 環境は複数の Conda および pip パッケージを含むように定義されていますが、計算ターゲットは省略されているため、デフォルトのローカル計算が使用されます。\n",
    "\n",
    "次のセルは、スクリプトベースの実験を構成して送信します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_experiment.py',\n",
    "                                environment=env)\n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace=ws, name='mslearn-diabetes')\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以前と同様に、ウィジェットまたは [Azure Machine Learning Studio](https://ml.azure.com) の実験へのリンクを使用して、実験によって生成された出力を表示したり、生成されたメトリックとファイルを取得するコードを記述したりできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は実行によっていくつかのログ ファイルが生成されている点に留意してください。これはウィジェットで表示したり、**get_details_with_logs** メソッドを使用したりできますが、今回は出力にログ データが含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_details_with_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログの詳細は上記の出力で表示できますが、通常はログ ファイルをダウンロードしてテキスト エディタで表示する方が簡単です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "log_folder = 'downloaded-logs'\n",
    "\n",
    "# Download all files\n",
    "run.get_all_logs(destination=log_folder)\n",
    "\n",
    "# Verify the files have been downloaded\n",
    "for root, directories, filenames in os.walk(log_folder): \n",
    "    for filename in filenames:  \n",
    "        print (os.path.join(root,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験実行履歴を表示する\n",
    "\n",
    "同じ実験を複数回実行したので、[Azure Machine Learning Studio](https://ml.azure.com) で履歴を表示し、記録された各実行を調べることができます。または、SDK を使用して、ワークスペースから名前で実験を取得し、実行を反復処理することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Run\n",
    "\n",
    "diabetes_experiment = ws.experiments['mslearn-diabetes']\n",
    "for logged_run in diabetes_experiment.get_runs():\n",
    "    print('Run ID:', logged_run.id)\n",
    "    metrics = logged_run.get_metrics()\n",
    "    for key in metrics.keys():\n",
    "        print('-', key, metrics.get(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow を使用する\n",
    "\n",
    "MLflow は、機械学習プロセスを管理するためのオープンソース プラットフォームです。これは、実験を調整し、メトリックを追跡するために、Databricks 環境で一般的に使用されます (ただし、排他的ではありません)。Azure Machine Learning の実験では、ネイティブ ログ機能の代わりに指標を追跡できます。\n",
    "\n",
    "この機能を利用するには、**azureml-mlflow** パッケージが必要なので、これらがインストールされていることを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show azureml-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インライン実験で MLflow を使用する\n",
    "\n",
    "MLflow を使用してインライン実験の指標を追跡するには、実験が実行されているワークスペースに MLflow *トラッキング URI* を設定する必要があります。これにより、**mlflow** トラッキング メソッドを使用して、実験の実行にデータを記録できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to the workspace\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
    "mlflow.set_experiment(experiment.name)\n",
    "\n",
    "# start the MLflow experiment\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    print(\"Starting experiment:\", experiment.name)\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "    # Count the rows and log the result\n",
    "    row_count = (len(data))\n",
    "    mlflow.log_metric('observations', row_count)\n",
    "    print(\"Run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは実行中にログされた指標を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest run of the experiment\n",
    "run = list(experiment.get_runs())[0]\n",
    "\n",
    "# Get logged metrics\n",
    "print(\"\\nMetrics:\")\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "    \n",
    "# Get a link to the experiment in Azure ML studio   \n",
    "experiment_url = experiment.get_portal_url()\n",
    "print('See details at', experiment_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードを実行した後、表示されるリンクを使用して、Azure Machine Learning Studio で実験を表示できます。次に、実験の最新の実行を選択し、その [**指標**] タブを表示して、ログに記録された指標を確認します。\n",
    "\n",
    "### 実験スクリプトで MLflow を使用する\n",
    "\n",
    "MLflow を使用して、実験スクリプトの指標を追跡することもできます。\n",
    "\n",
    "次の 2 つのセルを実行して、MLflow を使用する実験用のフォルダーとスクリプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "folder_name = 'mlflow-experiment-files'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/diabetes.csv', os.path.join(folder_name, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $folder_name/mlflow_diabetes.py\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# start the MLflow experiment\n",
    "with mlflow.start_run():\n",
    "       \n",
    "    # Load data\n",
    "    data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "    # Count the rows and log the result\n",
    "    row_count = (len(data))\n",
    "    print('observations:', row_count)\n",
    "    mlflow.log_metric('observations', row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure ML 実験スクリプトで MLflow トラッキングを使用する場合、実験の実行を開始すると、MLflow トラッキング URI が自動的に設定されます。ただし、スクリプトを実行する環境には、必要な **mlflow** パッケージが含まれている必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_mlflow = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='mlflow_diabetes.py',\n",
    "                                environment=env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace=ws, name='mslearn-diabetes-mlflow')\n",
    "run = experiment.submit(config=script_mlflow)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いつものように、実験の実行が終了すると、ログに記録されたメトリックを取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **詳細情報**: 実験の実行の詳細については、Azure ML のドキュメントの[このトピック](https://docs.microsoft.com/azure/machine-learning/how-to-manage-runs)を参照してください。実行でのメトリックの記録方法の詳細については、[このトピック](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments)を参照してください。Azure ML の実験と MLflow の統合の詳細については、[このトピック](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow)を参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}