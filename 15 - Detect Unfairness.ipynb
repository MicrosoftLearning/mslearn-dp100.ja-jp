{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# モデルの不公平性を検出して軽減する\r\n",
        "\r\n",
        "機械学習モデルには意図しないバイアスが組み込まれていることがあり、*公平性* の問題につながる可能性があります。たとえば、糖尿病の可能性を予測するモデルは、一部の年齢層ではうまく機能しても、他の年齢層ではうまく機能しないかもしれません。そのため、一部の患者が不必要な検査を受けたり、糖尿病の診断を確定する検査を受けられなかったりする可能性があります。\r\n",
        "\r\n",
        "このノートブックでは、**Fairlearn** パッケージを使用してモデルを分析し、年齢に基づいて患者の異なるサブセットの予測パフォーマンスの格差を探ります。\r\n",
        "\r\n",
        "> **注**: Fairlearn パッケージとの統合は、現在プレビュー中です。予期しないエラーが発生する場合があります。\r\n",
        "\r\n",
        "## 重要 - 公平性への配慮\r\n",
        "\r\n",
        "> このノートブックは、Fairlearn パッケージと Azure Machine Learning との統合を探索するための実践的な演習として設計されています。しかし、組織やデータ サイエンス チームがツールを使用する前に、公平性に関して議論しなければならない考慮事項は非常に多くあります。公平性は、単にモデルを分析するツールを実行するだけにとどまらない、複雑な *社会技術的* 課題です。\r\n",
        ">\r\n",
        "> Microsoft Research は 1 行のコードが記述される前に行われる必要がある重要な議論の出発点となる [公平性チェックリスト](https://www.microsoft.com/en-us/research/publication/co-designing-checklists-to-understand-organizational-challenges-and-opportunities-around-fairness-in-ai/) を共同開発しました。\r\n",
        "\r\n",
        "## 必要な SDK をインストールする\r\n",
        "\r\n",
        "Azure Machine Learning で Fairlearn パッケージを使用するには、Azure Machine Learning と Fairlearn Python パッケージが必要なので、次のセルを実行して **azureml-contrib-fairness** パッケージがインストールされていることを確認します。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip show azureml-contrib-fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "また、**fairlearn** パッケージ自体と **raiwidgets** パッケージ（Fairlearn がダッシュボードを視覚化するために使用する）も必要となります。インストールするには次のセルを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade fairlearn==0.7.0 raiwidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデルをトレーニングする\r\n",
        "\r\n",
        "まず、糖尿病の可能性を予測するための分類モデルをトレーニングします。データを特徴およびラベルのトレーニング セットとテスト セットに分割するだけでなく、公平性を比較するデータの部分母集団を定義するために使用される *センシティブ* 特徴を抽出します。この例では、**Age** 列を使用して、50歳を超える患者と50歳以下の患者という二つのカテゴリを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Get sensitive features\n",
    "S = data[['Age']].astype(int)\n",
    "# Change value to represent age groups\n",
    "S['Age'] = np.where(S.Age > 50, 'Over 50', '50 or younger')\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test, S_train, S_test = train_test_split(X, y, S, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "diabetes_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "モデルのトレーニングが完了したので、Fairlearn パッケージを使用して、さまざまなセンシティブ特徴値に対する動作を比較できます。この例では、以下のことを行います。\r\n",
        "\r\n",
        "- fairlearn **selection_rate** 関数を使用して、母集団全体の選択率 (正の予測の割合) を返します。\r\n",
        "- **scikit-learn** メトリック関数を使用して、全体的な精度、再現率、適合率のメトリックを計算します。\r\n",
        "- **MetricFrame** を使用して、**Age** のセンシティブ特徴の各年齢層の選択率、精度、再現率および適合率を計算します。パフォーマンス値の計算には、**fairlearn** と **scikit-learn** のメトリック関数を組み合わせて使用することに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import selection_rate, MetricFrame\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Get predictions for the witheld test data\n",
    "y_hat = diabetes_model.predict(X_test)\n",
    "\n",
    "# Get overall metrics\n",
    "print(\"Overall Metrics:\")\n",
    "# Get selection rate from fairlearn\n",
    "overall_selection_rate = selection_rate(y_test, y_hat) # Get selection rate from fairlearn\n",
    "print(\"\\tSelection Rate:\", overall_selection_rate)\n",
    "# Get standard metrics from scikit-learn\n",
    "overall_accuracy = accuracy_score(y_test, y_hat)\n",
    "print(\"\\tAccuracy:\", overall_accuracy)\n",
    "overall_recall = recall_score(y_test, y_hat)\n",
    "print(\"\\tRecall:\", overall_recall)\n",
    "overall_precision = precision_score(y_test, y_hat)\n",
    "print(\"\\tPrecision:\", overall_precision)\n",
    "\n",
    "# Get metrics by sensitive group from fairlearn\n",
    "print('\\nMetrics by Group:')\n",
    "metrics = {'selection_rate': selection_rate,\n",
    "           'accuracy': accuracy_score,\n",
    "           'recall': recall_score,\n",
    "           'precision': precision_score}\n",
    "\n",
    "group_metrics = MetricFrame(metrics=metrics,\n",
    "                             y_true=y_test,\n",
    "                             y_pred=y_hat,\n",
    "                             sensitive_features=S_test['Age'])\n",
    "\n",
    "print(group_metrics.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "これらのメトリックから、高齢患者の大部分が糖尿病であると予測されることがわかるはずです。*精度* は 2 つのグループでほぼ同じですが、*精度* と *再現率* を詳しく調べると、各年齢層でのモデルの予測精度に多少の格差があることがわかります。\r\n",
        "\r\n",
        "このシナリオでは、*再現率* を検討します。このメトリックは、モデルによって正しく識別された陽性症例の割合を示します。つまり、実際に糖尿病にかかっているすべての患者のうち、モデルに検出された人数です。このモデルは、若年患者よりも高齢患者の方がこの点で優れた結果を示しました。\r\n",
        "\r\n",
        "多くの場合、メトリックを視覚的に比較する方が簡単です。これを行うには、Fairlearn 公平性ダッシュボードを使用します。\r\n",
        "\r\n",
        "1. 下のセルを実行して、前に作成したモデルからダッシュボードを生成します。\r\n",
        "2. ウィジェットが表示されたら、**はじめに** リンクを使用して視覚化の設定を開始します。\r\n",
        "3. 比較するセンシティブ特徴を選択します (この例では、次の 1 つだけです: **年齢**)。\r\n",
        "4. 比較するモデル パフォーマンス メトリックを選択します (この場合は二項分類モデルであるため、オプションは *精度*、*均衡の取れた精度*、*適合率*、*再現率* です)。**再現率** から始めます。\r\n",
        "5. 表示する公平性比較のタイプを選択します。**人口統計学的パリティの違い**から始めましょう。\r\n",
        "6. ダッシュボードの視覚化を表示します。次の内容が表示されます。\r\n",
        "    - **パフォーマンスの格差** - *予測不足* (偽陰性) や *予測過剰* (偽陽性) などの部分母集団と比較した、選択したパフォーマンス メトリック。\r\n",
        "    - **予測の格差** - 部分母集団あたりの陽性症例数の比較。\r\n",
        "7. 構成を編集して、異なるパフォーマンスと公平性メトリックに基づく予測を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import FairnessDashboard\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairnessDashboard(sensitive_features=S_test,\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"diabetes_model\": diabetes_model.predict(X_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "その結果、50 歳以上の患者の方が若年患者よりも選択率がはるかに高くなっています。しかし、実際には年齢は糖尿病の正真正銘の要因なので、高齢患者の方が陽性症例が多くなることが予想されます。\r\n",
        "\r\n",
        "モデルのパフォーマンスを *精度* (つまり、モデルが正しく予測される割合) に基づいて判断すると、どちらの部分母集団に対してもほぼ同等に機能するように思われます。しかし、*適合率* と *再現率* のメトリックに基づくと、このモデルは 50 歳以上の患者でより良いパフォーマンスを示す傾向があります。\r\n",
        "\r\n",
        "モデルをトレーニングするときに **年齢** 特徴を除外するとどうなるか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "ageless = features.copy()\n",
    "ageless.remove('Age')\n",
    "X2, y2 = data[ageless].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train2, X_test2, y_train2, y_test2, S_train2, S_test2 = train_test_split(X2, y2, S, test_size=0.20, random_state=0, stratify=y2)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "ageless_model = DecisionTreeClassifier().fit(X_train2, y_train2)\n",
    "print(\"Model trained.\")\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairnessDashboard(sensitive_features=S_test2,\n",
    "                   y_true=y_test2,\n",
    "                   y_pred={\"ageless_diabetes_model\": ageless_model.predict(X_test2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "ダッシュボードのモデルを探索します。\r\n",
        "\r\n",
        "*再現率* を見直す際には、このモデルが高齢患者の陽性症例を有意に過小評価しているため、格差は減少していますが、全体的な再現率も減少していることに注意します。**年齢** はトレーニングで使用された特徴ではありませんでしたが、このモデルは高齢患者と若年患者を予測する際に若干の格差を示しています。\r\n",
        "\r\n",
        "このシナリオでは、**年齢** を削除するだけで、*再現率* の格差はわずかに減少しますが、*適合率* と *精度* の格差が大きくなります。これは、機械学習モデルに公平性を適用する際の重要な問題の 1 つを強調しています。特定のコンテキストにおいて *公平性* が何を意味するのかを明確にし、そのために最適化する必要があります。\r\n",
        "\r\n",
        "## モデルを登録し、ダッシュボード データをワークスペースにアップロードします。\r\n",
        "\r\n",
        "このノートブックでモデルをトレーニングし、ダッシュボードをローカルで確認しました。しかし、Azure Machine Learning ワークスペースにモデルを登録し、ダッシュボード データを記録する実験を作成すると、公平性分析を追跡して共有できるので便利かもしれません。\r\n",
        "\r\n",
        "まずは元のモデル (特徴として **年齢** が含まれていました) を登録してみましょう。\r\n",
        "\r\n",
        "> **注**: Azure サブスクリプションでまだ認証済みのセッションを確立していない場合は、リンクをクリックして認証コードを入力し、Azure にサインインして認証するよう指示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the Azure ML workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=diabetes_model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "registered_model = Model.register(model_path=model_file,\n",
    "                                  model_name='diabetes_classifier',\n",
    "                                  workspace=ws)\n",
    "model_id= registered_model.id\n",
    "\n",
    "\n",
    "print('Model registered.', model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "これで、FairLearn パッケージを使用して 1 つ以上のモデルの二項分類グループ メトリック セットを作成し、Azure Machine Learning 実験を使用してメトリックをアップロードできるようになりました。\r\n",
        "\r\n",
        "> **注**: これには時間がかかる場合があり、警告メッセージが表示される場合もあります（無視する）。実験が完了すると、ダッシュボード データがダウンロードされて表示され、正常にアップロードされたことを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics._group_metric_set import _create_group_metric_set\n",
    "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id\n",
    "\n",
    "#  Create a dictionary of model(s) you want to assess for fairness \n",
    "sf = { 'Age': S_test.Age}\n",
    "ys_pred = { model_id:diabetes_model.predict(X_test) }\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                    predictions=ys_pred,\n",
    "                                    sensitive_features=sf,\n",
    "                                    prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, 'mslearn-diabetes-fairness')\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness insights of Diabetes Classifier\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "\n",
    "    # To test the dashboard, you can download it\n",
    "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\n",
    "    print(downloaded_dict)\n",
    "finally:\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "上記のコードは、正常に完了したことを確認するためだけに、実験で生成されたメトリックをダウンロードしました。メトリックを実験にアップロードすることの本当の利点は、Azure Machine Learning Studio で FairLearn ダッシュボードを表示できるようになったことです。\r\n",
        "\r\n",
        "下のセルを実行して実験の詳細を確認し、ウィジェットの **View Run details** (実行の詳細を表示する) リンクをクリックして Azure Machine Learning Studio での実行を確認します。次に、実験実行の **公平性** タブを表示してアップロードしたメトリックに割り当てられた公平性 ID のダッシュボードを表示します。ダッシュボードは、このノートブックで以前表示したウィジェットと同じように動作します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "Azure Machine Learning Studio の **モデル** ページでモデルを選択し、**公平性** タブを見ることで、公平性ダッシュボードを見つけることもできます。これにより、組織はトレーニングおよび登録するモデルの公平性分析のログを保持できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## モデルの不公正性を軽減する\r\n",
        "\r\n",
        "これでモデルの公平性を分析できたので、FairLearn パッケージでサポートされている *軽減* 技術のいずれかを使用して、予測パフォーマンスと公平性のバランスを取るモデルを見つけることができます。\r\n",
        "\r\n",
        "この演習では、**GridSearch** 機能を使用します。この機能は、データセット内のセンシティブ特徴 (この場合、年齢層) の予測パフォーマンスの格差を最小限に抑えるために、複数のモデルをトレーニングします。**EqualizedOdds** パリティ制約を適用してモデルを最適化します。これは、センシティブ特徴グループごとに、モデルが同じような真陽性率と偽陽性率を示すようにするものです。 \r\n",
        "\r\n",
        "> *実行に時間がかかる場合があります*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print('Finding mitigated models...')\n",
    "\n",
    "# Train multiple models\n",
    "sweep = GridSearch(DecisionTreeClassifier(),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=20)\n",
    "\n",
    "sweep.fit(X_train, y_train, sensitive_features=S_train.Age)\n",
    "models = sweep.predictors_\n",
    "\n",
    "# Save the models and get predictions from them (plus the original unmitigated one for comparison)\n",
    "model_dir = 'mitigated_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_name = 'diabetes_unmitigated'\n",
    "print(model_name)\n",
    "joblib.dump(value=diabetes_model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "predictions = {model_name: diabetes_model.predict(X_test)}\n",
    "i = 0\n",
    "for model in models:\n",
    "    i += 1\n",
    "    model_name = 'diabetes_mitigated_{0}'.format(i)\n",
    "    print(model_name)\n",
    "    joblib.dump(value=model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "    predictions[model_name] = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "これで FairLearn ダッシュボードを使用して、軽減されたモデルを比較できるようになりました。\r\n",
        "\r\n",
        "次のセルを実行し、ウィザードを使用して **再現率**.別の **年齢** を視覚化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairnessDashboard(sensitive_features=S_test,\n",
    "                   y_true=y_test,\n",
    "                   y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "モデルは散布図に示されています。モデルを比較するには、予測の格差 (つまり選択率) または選択したパフォーマンス メトリックの格差 (この場合、*再現率*) を測定します。このシナリオでは、選択率の格差が予想されます (糖尿病では年齢*が*要因であることがわかっているので、年齢層が高いほど陽性症例が多くなります)。ここで注目したいのは、予測パフォーマンスの格差です。そこで、**再現率の不均衡** を測定するオプションを選択します。\r\n",
        "\r\n",
        "グラフは、X 軸に全体的な *再現率* メトリック、Y 軸に再現率の格差を持つモデルのクラスターを示しています。したがって、理想的なモデル (再現率が高く、格差が小さい) は、プロットの右下にあります。特定のニーズに適した予測パフォーマンスと公平性のバランスを選択し、適切なモデルを選択してその詳細を確認できます。\r\n",
        "\r\n",
        "強調すべき重要な点は、モデルに公平性の軽減を適用することは、全体的な予測パフォーマンスとセンシティブ特徴グループ間の格差との間のトレードオフであるということです。一般的には、モデルが母集団のすべてのセグメントに対して公平に予測することを保証するために、全体的な予測パフォーマンスを犠牲にする必要があります。\r\n",
        "\r\n",
        "> **注**: *適合率* メトリックを表示すると、予測されるサンプルがないために適合率が 0.0 に設定されているという警告が表示される場合があります。これは無視してかまいません。\r\n",
        "\r\n",
        "## Azure Machine Learning に軽減ダッシュボード メトリックをアップロードする\r\n",
        "\r\n",
        "前述のように、軽減の実験を追跡することもできます。これを行うには、次を実行します。\r\n",
        "\r\n",
        "1. GridSearch プロセスで検出されたモデルを登録します。\r\n",
        "2. モデルのパフォーマンスおよび格差メトリックを計算します。\r\n",
        "3. Azure Machine Learning の実験にメトリックをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the models\n",
    "registered_model_predictions = dict()\n",
    "for model_name, prediction_data in predictions.items():\n",
    "    model_file = os.path.join(model_dir, model_name + \".pkl\")\n",
    "    registered_model = Model.register(model_path=model_file,\n",
    "                                      model_name=model_name,\n",
    "                                      workspace=ws)\n",
    "    registered_model_predictions[registered_model.id] = prediction_data\n",
    "\n",
    "#  Create a group metric set for binary classification based on the Age feature for all of the models\n",
    "sf = { 'Age': S_test.Age}\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                     predictions=registered_model_predictions,\n",
    "                                     sensitive_features=sf,\n",
    "                                     prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, \"mslearn-diabetes-fairness\")\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness Comparison of Diabetes Models\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "finally:\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "> **注**: 予測されるサンプルがないために適合率が 0.0 に設定されているという警告が表示される場合があります。これは無視してかまいません。\r\n",
        "\r\n",
        "\r\n",
        "実験が終了したら、ウィジェットの **View Run details** (実行の詳細を表示する) リンクをクリックして Azure Machine Learning Studio（ウィジェットを表示するには、最初の出力を超えてスクロールする必要がある場合があります）での実行を確認し、**公平性** タブの FairLearn ダッシュボードを表示します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}